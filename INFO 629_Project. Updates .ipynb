{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "901c1172-61e4-4587-bb65-74dfd1888d35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T20:55:56.127155Z",
     "iopub.status.busy": "2026-02-28T20:55:56.126857Z",
     "iopub.status.idle": "2026-02-28T20:55:57.524357Z",
     "shell.execute_reply": "2026-02-28T20:55:57.523709Z",
     "shell.execute_reply.started": "2026-02-28T20:55:56.127134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:\n",
      "/home/c2631990-ebe7-45de-91d9-dcf1fee5926b\n",
      "Done merging!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"Current working directory:\")\n",
    "print(os.getcwd())\n",
    "\n",
    "data1 = pd.read_csv(\"cleanData.csv\")\n",
    "data2 = pd.read_csv(\"Mental_Health_and_Social_Media_Balance_Dataset.csv\")\n",
    "\n",
    "combined = pd.concat([data1, data2])\n",
    "\n",
    "# Create the 'processed' directory if it doesn't exist\n",
    "os.makedirs(\"processed\", exist_ok=True)  # 'exist_ok=True' prevents error if directory already exists\n",
    "\n",
    "combined.to_csv(\"processed/combined.csv\", index=False)\n",
    "\n",
    "print(\"Done merging!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78622fab-4148-46a9-82f6-8f6d51a608ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T20:56:06.152525Z",
     "iopub.status.busy": "2026-02-28T20:56:06.152198Z",
     "iopub.status.idle": "2026-02-28T20:56:06.643702Z",
     "shell.execute_reply": "2026-02-28T20:56:06.643047Z",
     "shell.execute_reply.started": "2026-02-28T20:56:06.152496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns:\n",
      "['index', 'statement', 'status', 'User_ID', 'Age', 'Gender', 'Daily_Screen_Time(hrs)', 'Sleep_Quality(1-10)', 'Stress_Level(1-10)', 'Days_Without_Social_Media', 'Exercise_Frequency(week)', 'Social_Media_Platform', 'Happiness_Index(1-10)']\n",
      "Using TEXT_COLUMN = statement\n",
      "Using LABEL_COLUMN = status\n",
      "Classes found: ['Anxiety', 'Bipolar', 'Depression', 'Normal', 'Personality disorder', 'Stress', 'Suicidal']\n",
      "Total rows used: 52680\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load merged dataset\n",
    "df = pd.read_csv(\"processed/combined.csv\")\n",
    "\n",
    "print(\"Available columns:\")\n",
    "print(list(df.columns))\n",
    "\n",
    "# --- Auto-detect TEXT column ---\n",
    "text_candidates = [\n",
    "    \"text\", \"Text\", \"statement\", \"Statement\", \"post\", \"Post\",\n",
    "    \"content\", \"Content\", \"message\", \"Message\", \"tweet\", \"Tweet\"\n",
    "]\n",
    "TEXT_COLUMN = next((c for c in text_candidates if c in df.columns), None)\n",
    "\n",
    "# If not found, guess: choose the object (string) column with the longest average text\n",
    "if TEXT_COLUMN is None:\n",
    "    obj_cols = [c for c in df.columns if df[c].dtype == \"object\"]\n",
    "    if not obj_cols:\n",
    "        raise ValueError(\"No text-like (object/string) columns found. Check your CSV.\")\n",
    "\n",
    "    avg_len = {}\n",
    "    for c in obj_cols:\n",
    "        s = df[c].astype(str).fillna(\"\")\n",
    "        avg_len[c] = s.str.len().mean()\n",
    "\n",
    "    TEXT_COLUMN = max(avg_len, key=avg_len.get)\n",
    "\n",
    "print(\"Using TEXT_COLUMN =\", TEXT_COLUMN)\n",
    "\n",
    "# --- Auto-detect LABEL column ---\n",
    "label_candidates = [\n",
    "    \"status\", \"Status\", \"label\", \"Label\", \"class\", \"Class\",\n",
    "    \"category\", \"Category\", \"target\", \"Target\"\n",
    "]\n",
    "LABEL_COLUMN = next((c for c in label_candidates if c in df.columns), None)\n",
    "\n",
    "# If not found, guess: pick a low-cardinality non-numeric column (but not the text column)\n",
    "if LABEL_COLUMN is None:\n",
    "    candidate_cols = [c for c in df.columns if c != TEXT_COLUMN]\n",
    "    best = None\n",
    "    best_score = -1\n",
    "    for c in candidate_cols:\n",
    "        # convert to string to handle mixed types\n",
    "        n_unique = df[c].astype(str).nunique(dropna=True)\n",
    "        # score labels as \"small number of unique classes\"\n",
    "        if 2 <= n_unique <= 20:\n",
    "            best = c\n",
    "            best_score = n_unique\n",
    "            break\n",
    "    if best is None:\n",
    "        raise ValueError(\n",
    "            \"Could not auto-detect label column. Please set LABEL_COLUMN manually \"\n",
    "            \"after looking at df.columns.\"\n",
    "        )\n",
    "    LABEL_COLUMN = best\n",
    "\n",
    "print(\"Using LABEL_COLUMN =\", LABEL_COLUMN)\n",
    "\n",
    "# Keep only needed columns and drop missing\n",
    "df2 = df[[TEXT_COLUMN, LABEL_COLUMN]].dropna()\n",
    "df2[TEXT_COLUMN] = df2[TEXT_COLUMN].astype(str)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df2[LABEL_COLUMN].astype(str))\n",
    "\n",
    "X = df2[TEXT_COLUMN]\n",
    "\n",
    "print(\"Classes found:\", list(le.classes_))\n",
    "print(\"Total rows used:\", len(df2))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba03532d-6ae5-40c3-8e60-38edd9f6c597",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T20:56:13.515018Z",
     "iopub.status.busy": "2026-02-28T20:56:13.514605Z",
     "iopub.status.idle": "2026-02-28T20:56:23.077450Z",
     "shell.execute_reply": "2026-02-28T20:56:23.076806Z",
     "shell.execute_reply.started": "2026-02-28T20:56:13.514987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB Accuracy: 0.6642938496583144\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.83      0.55      0.66       768\n",
      "             Bipolar       0.94      0.32      0.48       555\n",
      "          Depression       0.50      0.81      0.62      3081\n",
      "              Normal       0.84      0.82      0.83      3269\n",
      "Personality disorder       1.00      0.04      0.08       215\n",
      "              Stress       0.96      0.04      0.08       518\n",
      "            Suicidal       0.72      0.56      0.63      2130\n",
      "\n",
      "            accuracy                           0.66     10536\n",
      "           macro avg       0.83      0.45      0.48     10536\n",
      "        weighted avg       0.73      0.66      0.65     10536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes Classifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Convert text to TF-IDF features\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english',\n",
    "    max_features=20000,\n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Naive Bayes\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict\n",
    "nb_preds = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Multinomial NB Accuracy:\", accuracy_score(y_test, nb_preds))\n",
    "print(classification_report(y_test, nb_preds, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8e4ca36-b0d5-4b5d-b831-8a964a1a1331",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T20:56:29.210323Z",
     "iopub.status.busy": "2026-02-28T20:56:29.210019Z",
     "iopub.status.idle": "2026-02-28T20:56:29.618378Z",
     "shell.execute_reply": "2026-02-28T20:56:29.617744Z",
     "shell.execute_reply.started": "2026-02-28T20:56:29.210301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['index', 'statement', 'status', 'User_ID', 'Age', 'Gender', 'Daily_Screen_Time(hrs)', 'Sleep_Quality(1-10)', 'Stress_Level(1-10)', 'Days_Without_Social_Media', 'Exercise_Frequency(week)', 'Social_Media_Platform', 'Happiness_Index(1-10)']\n",
      "Using TEXT_COLUMN = statement\n",
      "Using LABEL_COLUMN = status\n",
      "Classes: ['Anxiety', 'Bipolar', 'Depression', 'Normal', 'Personality disorder', 'Stress', 'Suicidal']\n",
      "Train size: 42144 Test size: 10536\n"
     ]
    }
   ],
   "source": [
    "# Deep Learning Neural Network\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\"processed/combined.csv\")\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# Try common column names (adjust if needed)\n",
    "text_candidates  = [\"text\",\"Text\",\"statement\",\"Statement\",\"post\",\"Post\",\"content\",\"Content\",\"message\",\"Message\"]\n",
    "label_candidates = [\"status\",\"Status\",\"label\",\"Label\",\"class\",\"Class\",\"category\",\"Category\",\"target\",\"Target\"]\n",
    "\n",
    "TEXT_COLUMN = next((c for c in text_candidates if c in df.columns), None)\n",
    "LABEL_COLUMN = next((c for c in label_candidates if c in df.columns), None)\n",
    "\n",
    "if TEXT_COLUMN is None or LABEL_COLUMN is None:\n",
    "    # fallback: pick likely text column as longest avg string column\n",
    "    obj_cols = [c for c in df.columns if df[c].dtype == \"object\"]\n",
    "    if TEXT_COLUMN is None:\n",
    "        TEXT_COLUMN = max(obj_cols, key=lambda c: df[c].astype(str).str.len().mean())\n",
    "    if LABEL_COLUMN is None:\n",
    "        # pick a low-cardinality column different from text\n",
    "        for c in obj_cols:\n",
    "            if c == TEXT_COLUMN: \n",
    "                continue\n",
    "            n = df[c].astype(str).nunique(dropna=True)\n",
    "            if 2 <= n <= 20:\n",
    "                LABEL_COLUMN = c\n",
    "                break\n",
    "\n",
    "print(\"Using TEXT_COLUMN =\", TEXT_COLUMN)\n",
    "print(\"Using LABEL_COLUMN =\", LABEL_COLUMN)\n",
    "\n",
    "df = df[[TEXT_COLUMN, LABEL_COLUMN]].dropna()\n",
    "df[TEXT_COLUMN] = df[TEXT_COLUMN].astype(str)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[LABEL_COLUMN].astype(str))\n",
    "X = df[TEXT_COLUMN]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Classes:\", list(le.classes_))\n",
    "print(\"Train size:\", len(X_train), \"Test size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f9984b4-aef2-483c-a65e-01bc8dc3e136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T20:56:40.572743Z",
     "iopub.status.busy": "2026-02-28T20:56:40.572450Z",
     "iopub.status.idle": "2026-02-28T20:57:29.720977Z",
     "shell.execute_reply": "2026-02-28T20:57:29.720393Z",
     "shell.execute_reply.started": "2026-02-28T20:56:40.572720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.6761 - loss: 0.8877 - val_accuracy: 0.7744 - val_loss: 0.6235\n",
      "Epoch 2/10\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.8489 - loss: 0.4224 - val_accuracy: 0.7708 - val_loss: 0.6353\n",
      "Epoch 3/10\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - accuracy: 0.9238 - loss: 0.2300 - val_accuracy: 0.7597 - val_loss: 0.7766\n",
      "Neural Network Accuracy: 0.7672740817070007\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.82      0.79      0.81       768\n",
      "             Bipolar       0.84      0.75      0.79       555\n",
      "          Depression       0.73      0.69      0.71      3081\n",
      "              Normal       0.87      0.94      0.90      3269\n",
      "Personality disorder       0.89      0.51      0.65       215\n",
      "              Stress       0.56      0.47      0.51       518\n",
      "            Suicidal       0.66      0.71      0.68      2130\n",
      "\n",
      "            accuracy                           0.77     10536\n",
      "           macro avg       0.77      0.69      0.72     10536\n",
      "        weighted avg       0.77      0.77      0.76     10536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Deep Learning Neural Network\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_cat  = to_categorical(y_test,  num_classes=num_classes)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(X_train_tfidf.shape[1],), sparse=True, name=\"tfidf\")\n",
    "x = layers.Dense(256, activation=\"relu\")(inputs)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_tfidf, y_train_cat,\n",
    "    validation_split=0.1,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "loss, acc = model.evaluate(X_test_tfidf, y_test_cat, verbose=0)\n",
    "print(\"Neural Network Accuracy:\", acc)\n",
    "\n",
    "probs = model.predict(X_test_tfidf, verbose=0)\n",
    "preds = np.argmax(probs, axis=1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, preds, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "979c73f4-ac93-429c-8621-32f05ddb45fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T20:57:36.226829Z",
     "iopub.status.busy": "2026-02-28T20:57:36.226251Z",
     "iopub.status.idle": "2026-02-28T20:57:36.231560Z",
     "shell.execute_reply": "2026-02-28T20:57:36.231044Z",
     "shell.execute_reply.started": "2026-02-28T20:57:36.226806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.6642938496583144\n",
      "Neural Network Accuracy: 0.7672740817070007\n"
     ]
    }
   ],
   "source": [
    "# Compare Models \n",
    "\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, nb_preds))\n",
    "print(\"Neural Network Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804d477f-d6b7-4907-900e-c461543714fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
